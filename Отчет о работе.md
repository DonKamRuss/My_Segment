## Этап 1. Исследовательский анализ (EDA)

### Анализ качества данных 

Датасет был просмотрен, прверена структура, расширения файлов.
СОзданы скрипты для просмотра картинок, идентификации классов - cat и dog
выполнен анализ классов
создан скрипт для просмотра изображений в датасете, позводляющий сразу удалять некорректные - удалены изображения с некорректными изображениями - там, где маски не соответствовали контурам и классам.

Наблюдается сильный дисбаланс. Класс 0 (фон) занимает около 90% всех пикселей, в то время как целевые классы 1 и 2 занимают лишь по 4-6% каждый. ЭТо будет учтено в дальнейшем.

Результаты представлены в ноутбуке. 

## Этап 2. Формирование первичных гипотез

Одним из главных условий, к сожалению, было то, то работа велась на CPU, в связи с отсутсвием возможности длительной работы с ВМ.
Поэтому необходимо было выбирать из mmsegmentation архитектуры с малым количеством параметров и эффективными операциями.
Поиск в сети с применением ИИ дал рекомендацию - : SegFormer (вариант B0):
-SegFormer не использует "Heavy" декодеры и свертки с большим dilation, что делает его быстрее на CPU;
- Трансформер (ViT-подобная) с иерархической структурой энкодера и легким MLP-декодером
    Энкодер: Mix Transformer (MiT-B0) с 4-мя ступенями разного разрешения
    Декодер: All-MLP — простой и эффективный, объединяет multi-scale фичи
    Позиционные энкодинги: Отсутствуют (используется positional-encoding-free design)
    Глобальный контекст: Самовнимание захватывает глобальные зависимости уже на ранних стадия


**Анализ качества**  

Анализ качества. Приложите метрики, примеры фейлов, примеры правильных ответов модели.  

**Эксперимент 0** 
В папке ЭТап 2 приведены используемые при обучении модели файлы из mmsegmentation
(segformer_b0_custom.py) - для обучения (my_Segment\Этап_2_Формирование первичных гипотез\my_mmsegmentation\configs)

Ссылка на результаты обучения
 https://app.clear.ml/projects/e87176d4b8d74d29ab62194591af9359/experiments/ccb3e18503f74886b3e0efcc5f1282e7/output/execution

тут возникла проблема, котрую решить не смог - не реализовались графики метрики (и возмущался clearML по поводу большого размера загружаемого файла)
Тем не менее:
Модель на 7000 итерации показала лучший результат.
•	iter_8000.pth — последний чекпоинт перед остановкой.
Итоги обучения
    Лучший mDice: 61.12% — не 75, конечно, но с учетом "небыстрого компа" для легкой модели, в учебных целях и, небольшого, в общем-то датасета, неплохо.
    Т.е. модель научилась стабильно выделять фон и объекты, но на 8000 итерации начала терять точность (возможно, "зазубривать" тренировочные данные).

2000 итераций      aAcc: 81.9300  mDice: 49.9800  mAcc: 58.2300  mIoU: 39.6800  data_time: 0.3306  time: 0.4138
4000 итераций      aAcc: 87.2800  mDice: 55.3200  mAcc: 62.6300  mIoU: 44.5200  data_time: 0.3358  time: 0.4284
6000 итараций      aAcc: 89.4700  mDice: 60.6200  mAcc: 62.6500  mIoU: 48.8300  data_time: 0.3311  time: 0.4127
7000 итераций      aAcc: 90.4500  mDice: 62.4400  mAcc: 62.6800  mIoU: 50.4300  data_time: 0.3352  time: 0.4216
8000 итерций       aAcc: 89.8400  mDice: 61.3600  mAcc: 63.2300  mIoU: 49.5100  data_time: 0.3329  time: 0.4192

Примечание. class_weight=[0.8, 1.0, 1.0]), # Веса из EDA [cite: 3]  0,8 - сделано для инференса при обучении было 0,1


## Этап 3. Эксперименты по улучшению качества

### Эксперимент 1 

В этом эксперименте пробовали работу с гиперпарметрами:
- применил по рекомендации сети "более агрессивную настройку для "головы" (декодера) модели: lr_mult=10.: 
    Декодер обучается с большим коэффициентом обучения в 10 раз, чем основная сеть - по идее - должно позволить сегментационной части быстрее адаптироваться к специфике датасета.
- снизил базовый lr сниен до 0.00006, что в сочетании с множителем для головы должно было дать более стабильное дообучение (fine-tuning).

**Результаты обучения**

ссылка на конфиг = segformer_b0_custom_2.py (my_Segment\Этап_2_Формирование первичных гипотез\my_mmsegmentation\configs)
ссылка на clearml = https://app.clear.ml/projects/e87176d4b8d74d29ab62194591af9359/experiments/7c3249f28eaa488fb1477219efded240/output/execution

6000 итераций - aAcc: 89.3200  mDice: 54.7700  mAcc: 53.6300  mIoU: 44.2000  data_time: 0.1374  time: 0.2179
7000 итераций - aAcc: 89.7100  mDice: 55.0200  mAcc: 52.8800  mIoU: 44.4400  data_time: 0.1471  time: 0.2300

после этого mDice не повышался - остановил эксперимент.

### Эксперимент 2 
Внесено архитектурные изменение (Dropout) (опять же, чтобы не усложнять модель и в разы не увеличивать время на обработку. И выполнить задание!)

Добавление слоя Dropout с коэффициентом 0.1 (10%) в декодер модели направлено на предотвращение переобучения: модель принудительно "отключает" часть нейронов во время обучения, чтобы не полагаться на конкретные пиксели или шумы в данных.

ссылка на конфиг = segformer_b0_custom_3.py (my_Segment\Этап_2_Формирование первичных гипотез\my_mmsegmentation\configs)
ссылка на clearml = https://app.clear.ml/projects/e87176d4b8d74d29ab62194591af9359/experiments/3acfad91084a454fb7c2dd99bea2e903/output/execution


## Этап 3. Заключение и выбор лучшего эксперимента

### Лучший эксперимент 

Кратко опишите параметры этого эксперимента и как вы пришли к нему.

Сводная таблица лучших показателей

Эксперимент	Итерации	aAcc (Общая)	mIoU (Осн. метрика)	mDice	Time (Скорость)
Эксперимент №0	7000	90.45	50.43	62.44	0.4216
Эксперимент №1	7000	89.71	44.44	55.02	0.2300
Эксперимент №2	6000	89.47	48.36	59.95	0.4219


Анализ динамики обучения
•	Переобучение в Эксперименте №0: (mIoU снижается с 50.43 до 49.51 к 8000 итерациям). Модель "переучилась", и 7000 итераций для данной конфигурации — это оптимальная точка остановки (early stopping).
•	Эксперимент №2  работает почти в 2 раза быстрее (time: 0.2300), но его точность (mIoU 44.44) существенно ниже. Его стоит выбирать только в том случае, если  критична скорость работы модели, а не  точность.
•	Эксперимент №3: неплохие результаты, но не достигает планки первого эксперимента ни по одной из ключевых метрик точности.

Итог

Опираясь на результаты проделанной работы в качестве лучшего - выбираем эксперимент №0 (т.е. превоначальный вариант) на 7000 итерациях. Он обеспечивает наилучший баланс между точностью классификации отдельных классов и точностью прорисовки границ объектов.

### Возможности для улучшения 

Пути улучшения в общем-то стандартные и, свящаны, прежде всего, с производительностью техники:
- если оставаться в segformer, можно  mit-b0 на mit-b1 и т.д....
- однозначно нужно поработать над датасетом
        обязательно проверить тщательно изображения и маски (не удалять, как я это сделал, а доразметить)
        обязательно добавить больше аугментаций
- ну ли радикально  -взять другю модель - ту же DeepLabv3+, которую изучали в курсе.

Итог
для инференса выбрал 
(segformer_b0_custom.py) - для обучения (my_Segment\Этап_2_Формирование первичных гипотез\my_mmsegmentation\configs) из эксперимента №0


### Этап4 Инфренс на тест

Результаты представлены в ноутбуках в папке Этап 5 Инференс

Первый запуск Inferens_final_1.ipynb показал
Анализ по классам:

  Background:
    Dice: 0.9278
    IoU:  0.8652
    Predicted pixels: 52,104 (79.5%)
    GT pixels:        59,094 (90.2%)

  Cat:
    Dice: 0.5929
    IoU:  0.4213
    Predicted pixels: 6,603 (10.1%)
    GT pixels:        6,442 (9.8%)

  Dog:
    Dice: 0.0000
    IoU:  0.0000
    Predicted pixels: 6,829 (10.4%)
    GT pixels:        0 (0.0%)

    для поиска причин еще раз проанализировал тест, чтоб убедиться в его корректности (Proverka_dataseta TEST собаки.ipynb)

    тогда сделал следующее:  Inferens_final_6.ipynb

    1 решена  проблема ложноположительных срабатываний (когда модель видит «собаку» там, где её нет или где это просто мелкий шум) решена с помощью метода фильтрации связных областей по их площади.
        def post_process_mask_fixed
            код выполняет постобработку результатов сегментации для борьбы с ложноположительными срабатываниями (шумом).
            цель — убрать с итогового изображения мелкие области, которые модель ошибочно приняла за собаку.
    2  заменил  lass_weight=[0.1, 1.0, 1.0]), на class_weight=[0.8, 1.0, 1.0]),
                - Снижение «агрессивности» подавления фона                
                    При весе 0.1 модель начинает «залезать» маской животного на окружающие предметы, так как штраф за ошибку на фоне минимален.
                    При весе 0.8 мы заставляеи модель проводить границы строже и аккуратнее.
                - Борьба с ложными срабатываниями
                    Если вес фона мал, модели «выгоднее» предсказать лишние пиксели животного (на всякий случай), чем пропустить их.
                    Увеличение веса фона до 0.8 заставляет модель быть более уверенной, прежде чем пометить пиксель как «собака» или «кошка».

ссылка на clearml  https://app.clear.ml/projects/e87176d4b8d74d29ab62194591af9359/experiments/79c33d2e52e7423eb1d7a3f5bcc0273b/output/execution
